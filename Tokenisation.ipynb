{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0itAGaPKwI7f/gNK72u2l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/V-Nayak/New-/blob/main/Tokenisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP\n",
        "1.Data Preprocessing.\n",
        "2.Algorithm Development.\n",
        "\n",
        "## **1.Data Preprocessing:**\n",
        "1.lower casing\n",
        "2.Tokensiation\n",
        "3 Punctuation Mark removal\n",
        "4 Stop word Removal\n",
        "5 Stemming/Lammetisation.\n",
        "\n",
        "## **2.Algorithm Development.**\n",
        "\n"
      ],
      "metadata": {
        "id": "-2T9YB2kJ048"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "aN2GLzSfKiky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lower casing\n",
        "sentence= \"Linguistics is the Scientific Study of Language\" ##L and S are Capital\n",
        "sentence = sentence.lower()\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRi7xAuuMUgS",
        "outputId": "d0a59c2f-2c20-41c2-fc1f-aec39193baf4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linguistics is the scientific study of language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenisation\n",
        "#sentence\n",
        "paragraph=\"Linguistics is the scientific study of language. It encompasses the analysis of every aspect of language, as well as the methods for studying and modeling them. The traditional areas of linguistic analysis include phonetics, phonology, morphology, syntax, semantics, and pragmatics.\"\n",
        "sentence = nltk.sent_tokenize(paragraph.lower())\n",
        "print(sentence)\n",
        "print(len(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYYsaGjXL1VQ",
        "outputId": "968d823d-e459-4622-cc6f-8d4ee514b7db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['linguistics is the scientific study of language.', 'it encompasses the analysis of every aspect of language, as well as the methods for studying and modeling them.', 'the traditional areas of linguistic analysis include phonetics, phonology, morphology, syntax, semantics, and pragmatics.']\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word\n",
        "words = nltk.word_tokenize(paragraph.lower())\n",
        "print(words)\n",
        "print(len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Gqaa3OWZQf",
        "outputId": "946dd923-5a23-4dfc-de49-4466953b14f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['linguistics', 'is', 'the', 'scientific', 'study', 'of', 'language', '.', 'it', 'encompasses', 'the', 'analysis', 'of', 'every', 'aspect', 'of', 'language', ',', 'as', 'well', 'as', 'the', 'methods', 'for', 'studying', 'and', 'modeling', 'them', '.', 'the', 'traditional', 'areas', 'of', 'linguistic', 'analysis', 'include', 'phonetics', ',', 'phonology', ',', 'morphology', ',', 'syntax', ',', 'semantics', ',', 'and', 'pragmatics', '.']\n",
            "49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Punctuation mark removal\n",
        "new_words = [word for word in words if word.isalnum()]\n",
        "print(new_words)\n",
        "print(len(new_words))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGBYQw0oX3z8",
        "outputId": "266ba2d2-45c1-45ff-e38b-831b990813cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['linguistics', 'is', 'the', 'scientific', 'study', 'of', 'language', 'it', 'encompasses', 'the', 'analysis', 'of', 'every', 'aspect', 'of', 'language', 'as', 'well', 'as', 'the', 'methods', 'for', 'studying', 'and', 'modeling', 'them', 'the', 'traditional', 'areas', 'of', 'linguistic', 'analysis', 'include', 'phonetics', 'phonology', 'morphology', 'syntax', 'semantics', 'and', 'pragmatics']\n",
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Stop word removal--helps in dimensionality reduction by eliminating unnecessary information\n",
        "nltk.corpus\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NboGrYPFbiI-",
        "outputId": "8cea2cc1-7886-4c3e-f323-fc40ae104e85"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words(\"english\"))\n",
        "print(len(stopwords.words(\"english\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL0S2it6b-d6",
        "outputId": "e1a331c3-8cdc-40bf-bd63-6acd25635cc9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words(\"spanish\"))\n",
        "print(len(stopwords.words(\"english\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aoXmrQ_coKq",
        "outputId": "ba4cb83d-6020-469c-823e-bf6a4f688b88"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n",
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words(\"french\"))\n",
        "print(len(stopwords.words(\"french\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ86igkqc1bx",
        "outputId": "4f828d26-c981-4b6f-be27-a20b31b6d8b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n",
            "157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordset = []\n",
        "for word in new_words :\n",
        "  if word not in set(stopwords.words(\"english\")):\n",
        "    wordset.append(word)\n",
        "print(wordset)\n",
        "print(len(wordset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRuZA1mCdniC",
        "outputId": "f7826a99-d861-4e2d-8472-6efb32fd67d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['linguistics', 'scientific', 'study', 'language', 'encompasses', 'analysis', 'every', 'aspect', 'language', 'well', 'methods', 'studying', 'modeling', 'traditional', 'areas', 'linguistic', 'analysis', 'include', 'phonetics', 'phonology', 'morphology', 'syntax', 'semantics', 'pragmatics']\n",
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "wordsetstem = []\n",
        "for word in wordset :\n",
        "  wordsetstem.append(ps.stem(word))\n",
        "print(wordsetstem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94b8nahFeT0X",
        "outputId": "28ffcaf5-b5bd-41e9-8146-e5ab31e0b86c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['linguist', 'scientif', 'studi', 'languag', 'encompass', 'analysi', 'everi', 'aspect', 'languag', 'well', 'method', 'studi', 'model', 'tradit', 'area', 'linguist', 'analysi', 'includ', 'phonet', 'phonolog', 'morpholog', 'syntax', 'semant', 'pragmat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##lematization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lm = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "\n",
        "wordSetLem = []\n",
        "for word in wordset :\n",
        "  wordSetLem.append(lm.lemmatize(word))\n",
        "print(wordSetLem)\n",
        "print(len(wordSetLem))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8hoThEigXv8",
        "outputId": "1501c112-eb64-4e18-c5cc-d5a9f736f715"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['linguistics', 'scientific', 'study', 'language', 'encompasses', 'analysis', 'every', 'aspect', 'language', 'well', 'method', 'studying', 'modeling', 'traditional', 'area', 'linguistic', 'analysis', 'include', 'phonetics', 'phonology', 'morphology', 'syntax', 'semantics', 'pragmatic']\n",
            "24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}